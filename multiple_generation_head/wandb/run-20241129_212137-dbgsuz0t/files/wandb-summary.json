{"step": 175, "val_loss": 4.3440022468566895, "val_loss_layer_7": 102.3265380859375, "val_loss_layer_8": 97.80375671386719, "val_loss_layer_9": 90.90081787109375, "val_loss_layer_10": 78.4738540649414, "val_loss_layer_11": 64.8952407836914, "_timestamp": 1732886740.5622694, "_runtime": 243.23478245735168, "_step": 211, "gpt2-multi-softmax_20241129_212136_generated_samples": {"_type": "table-file", "sha256": "e9092fb923624dc5f1be468c449eca78e2d3ed205f79b45029b4206b148898b9", "size": 1070, "artifact_path": "wandb-client-artifact://ej2hzpa8sh4qeul5q71ehraahc18uin52h7ml14ygzs7uk2bxtdwjn02xmds277vsbjw49lk9os0z19ok87wkp62s9qop34x7bcx5nsmye3hsorqhta7an0oycx8qyol/gpt2-multi-softmax_20241129_212136_generated_samples.table.json", "_latest_artifact_path": "wandb-client-artifact://suofybovjqhkvjivo27a57f6a40xs0tu502gvrth2wgear2pmp5awugfdizyyw9ar7r31ecvq04lh8456fo04bf5qx9a037v8i5h158yx75pdmga46lmz44zlj6t3vwp:latest/gpt2-multi-softmax_20241129_212136_generated_samples.table.json", "path": "media/table/gpt2-multi-softmax_20241129_212136_generated_samples_205_e9092fb923624dc5f1be.table.json", "ncols": 4, "nrows": 5}, "train_loss": 4.225887298583984, "learning_rate": 0.00014769230769230766, "grad_norm": 0.3927210867404938, "tokens_per_sec": 594748.3801600097, "loss_layer_7": 19.884363174438477, "loss_layer_8": 19.004959106445312, "loss_layer_9": 17.61754035949707, "loss_layer_10": 15.27663803100586, "loss_layer_11": 12.734244346618652, "_wandb": {"runtime": 242}}