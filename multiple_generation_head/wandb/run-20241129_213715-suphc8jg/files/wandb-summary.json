{"step": 1798, "val_loss": 3.3865561485290527, "val_loss_layer_7": 3.8462002277374268, "val_loss_layer_8": 3.502990961074829, "val_loss_layer_9": 3.3333165645599365, "val_loss_layer_10": 3.1779205799102783, "val_loss_layer_11": 3.0723519325256348, "_timestamp": 1732888470.7756155, "_runtime": 1035.0528824329376, "_step": 2158, "gpt2-multi-softmax_20241129_213713_generated_samples": {"_type": "table-file", "sha256": "75757349132bb8293fabaafcbe640bf0ecc1d9e33b3a06858143342f901bcd3c", "size": 1051, "artifact_path": "wandb-client-artifact://nw0r3tbstutne7diruqt0pf6ctan4opn1jnsq6jrx9wz1oavere7rhzk57dsw0ykixwofswinj1du2mlq46l9vfoft85aisamr0y74ihuwovue4oyinbiy4ozsc872ie/gpt2-multi-softmax_20241129_213713_generated_samples.table.json", "_latest_artifact_path": "wandb-client-artifact://8acv8feegnjkh4f51xdihdm3nc9nfznwwatvvn7p0ngy99nn4uf1ryud1mh3m2osnjjb3eems41fe5v8xmbe1nqtq8sj1ejp2d0u8dowmjw2v096cagwxz5chgw83k8q:latest/gpt2-multi-softmax_20241129_213713_generated_samples.table.json", "path": "media/table/gpt2-multi-softmax_20241129_213713_generated_samples_2149_75757349132bb8293fab.table.json", "ncols": 4, "nrows": 5}, "train_loss": 3.3535521030426025, "learning_rate": 0.0005953762299058733, "grad_norm": 0.039331547915935516, "tokens_per_sec": 1550499.0985850347, "loss_layer_7": 3.7911250591278076, "loss_layer_8": 3.4640307426452637, "loss_layer_9": 3.3039064407348633, "loss_layer_10": 3.15616774559021, "loss_layer_11": 3.052530527114868}