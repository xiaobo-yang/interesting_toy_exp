{"step": 139, "val_loss": 4.570280075073242, "val_loss_layer_7": 5.516208648681641, "val_loss_layer_8": 5.237941265106201, "val_loss_layer_9": 4.798751354217529, "val_loss_layer_10": 4.0456461906433105, "val_loss_layer_11": 3.252854108810425, "_timestamp": 1732887093.819755, "_runtime": 191.61760902404785, "_step": 167, "gpt2-multi-softmax_20241129_212819_generated_samples": {"_type": "table-file", "sha256": "efe8859348c8bf6c46e70f1e2a8e8f4c8fc02402851d72174466027eab2fbebe", "size": 1037, "artifact_path": "wandb-client-artifact://bz88lshlqggpps2icq3a6qsbjucfrdrq4vj35csm5h99xefotrlyu5trvoum9ll98534ed6zzhdhywvdn3vcjk8100wq56rc4q9t0sfc0byfhnfycasxwy43rbs5ggod/gpt2-multi-softmax_20241129_212819_generated_samples.table.json", "_latest_artifact_path": "wandb-client-artifact://hmiek3417n1fd8x95x28hgmwlac9qfrl9e9su4bc8twtux0ub7hpq777rbsw4zkinri7dc0u0ianj4m3bbdwrsu7umaplaq73wdukfc3p6vp2d01zdfqls3rw8r24foh:latest/gpt2-multi-softmax_20241129_212819_generated_samples.table.json", "path": "media/table/gpt2-multi-softmax_20241129_212819_generated_samples_157_efe8859348c8bf6c46e7.table.json", "ncols": 4, "nrows": 5}, "train_loss": 4.522874355316162, "learning_rate": 0.00011748251748251747, "grad_norm": 0.39648351073265076, "tokens_per_sec": 594385.389451298, "loss_layer_7": 5.402336120605469, "loss_layer_8": 5.1467976570129395, "loss_layer_9": 4.750162124633789, "loss_layer_10": 4.043985366821289, "loss_layer_11": 3.2710893154144287, "_wandb": {"runtime": 190}}